# AgentCodeEval Configuration File
# PRODUCTION FULL-SCALE CONFIGURATION
# For massive-scale agent evaluation with 12,000 instances

api:
  # API Keys (set via environment variables for security)
  # openai_api_key: "your-openai-key-here"
  # anthropic_api_key: "your-anthropic-key-here" 
  # google_api_key: "your-google-key-here"
  # huggingface_token: "your-hf-token-here"
  
  # Rate limiting settings (optimized for production)
  max_requests_per_minute: 600
  max_concurrent_requests: 60
  
  # Default models - üèÜ 3 Elite Models
  default_model_openai: "o3"                                  # ‚úÖ Elite: OpenAI o3 (reasoning model)
  default_model_anthropic: "claude-sonnet-4-20250514"         # ‚úÖ Elite: Claude Sonnet 4 via AWS Bedrock
  default_model_google: "gemini-2.5-pro"                      # ‚úÖ Elite: Gemini 2.5 Pro (latest)

data:
  # Local storage directories
  output_dir: "./data/output"
  generated_dir: "./data/generated"
  
  # Synthetic generation settings
  supported_languages:
    - python      # #1: AI/ML dominance (23.88%, +8.72% growth)
    - cpp         # #2: High-performance, games, systems (11.37%, +0.84% growth)  
    - java        # #3: Enterprise, Android (10.66%, +1.79% growth)
    - c           # #4: Systems programming (9.84%, declining but essential)
    - csharp      # #5: Enterprise, Windows (.NET) (4.12%, Microsoft ecosystem)
    - javascript  # #6: Web standard, frontend/backend (3.78%, +0.61% growth)
    - typescript  # JS ecosystem: Enterprise web, type safety (75% of React projects)
    - go          # #8: Cloud-native, microservices (2.26%, +0.53% growth)
    - rust        # #13: Systems, security, performance (1.47%, +0.42% growth)
    - php         # #14: Web development, still widely used (1.14%, legacy but prevalent)
  
  # Project generation criteria (OPTIMIZED FOR 10 LANGUAGES)
  min_files_per_project: 10
  max_files_per_project: 100
  projects_per_language: 100  # OPTIMAL: 10 languages √ó 100 = 1,000 total projects
  
  # Complexity levels for synthetic projects
  complexity_distribution:
    easy: 0.25      # 25% easy projects
    medium: 0.25    # 25% medium projects
    hard: 0.25     # 25% hard projects
    expert: 0.25    # 25% expert projects
  
  # Generation quality controls
  min_complexity_score: 0.3
  max_complexity_score: 0.9
  min_documentation_ratio: 0.03  # Lowered from 0.1 to match realistic generation

benchmark:
  # Scale parameters (OPTIMIZED FOR 10 LANGUAGES)
  total_instances: 8000  # 1,000 projects √ó 8 categories = 8,000 evaluation scenarios
  
  # Task category distribution (must sum to total_instances)
  task_distribution:
    architectural_understanding: 1000    # Deep architectural analysis
    cross_file_refactoring: 1000        # Multi-file code restructuring
    feature_implementation: 1000        # Complex feature development
    bug_investigation: 1000             # Real-world debugging scenarios
    multi_session_development: 1000     # Long-term development projects
    code_comprehension: 1000            # Large codebase understanding
    integration_testing: 1000           # System integration validation
    security_analysis: 1000             # Security vulnerability assessment
  
  # Difficulty distribution (must sum to total_instances)
  difficulty_distribution:
    easy: 2000      # 10K-100K tokens 
    medium: 2000    # 100K-200K tokens
    hard: 2000      # 200K-500K tokens 
    expert: 2000    # 500K-1000K tokens 
  
  # Context length ranges (min_tokens, max_tokens) - PRODUCTION SCALE
  context_ranges:
    easy: [10000, 100000]       # Small to medium codebases
    medium: [100000, 200000]    # Medium to large codebases
    hard: [200000, 500000]     # Large enterprise codebases
    expert: [500000, 1000000]   # Massive enterprise systems
  
  # Information coverage requirements (PRODUCTION QUALITY)
  min_information_coverage: 0.7
  target_information_coverage:
    easy: 0.75      # Good coverage for simple tasks
    medium: 0.85    # High coverage for complex tasks
    hard: 0.90      # Very high coverage for difficult tasks
    expert: 0.95    # Near-complete coverage for expert tasks

evaluation:
  # Metric weights for CADS (Composite Agent Development Score)
  # Must sum to 1.0
  metric_weights:
    architectural_coherence: 0.20      # ACS: System design understanding
    dependency_traversal: 0.20         # DTA: Cross-file navigation
    multi_session_memory: 0.20         # MMR: Long-term context retention
    cross_file_reasoning: 0.15         # CFRD: Multi-file logic integration
    incremental_development: 0.15      # IDC: Progressive development capability
    information_coverage: 0.10         # ICU: Information utilization efficiency
  
  # Scoring thresholds
  score_thresholds:
    excellent:
      min: 4.0
      max: 5.0
    good:
      min: 3.0
      max: 4.0
    fair:
      min: 2.0
      max: 3.0
    poor:
      min: 0.0
      max: 2.0
  
  # Timeout settings (seconds) - PRODUCTION TIMEOUTS
  task_timeout: 1800      # 30 minutes per task
  session_timeout: 3600  # 60 minutes per session 